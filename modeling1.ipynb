{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95f6984f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[TEAM NORMALIZATION FAILED FOR THESE RAW VALUES]\n",
      "team_raw\n",
      "Ե ̾    23\n",
      "ȭ̱۽    22\n",
      "Ű      22\n",
      "λ꺣    22\n",
      "Ｚ̿     17\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Some team names could not be normalized. Add patterns to TEAM_RULES.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 77\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28mprint\u001b[39m(failed\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m30\u001b[39m))\n\u001b[1;32m     76\u001b[0m \u001b[38;5;66;03m# If normalization still fails for some values, STOP and add them to TEAM_RULES.\u001b[39;00m\n\u001b[0;32m---> 77\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mteam_norm\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mnotna()\u001b[38;5;241m.\u001b[39mall(), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSome team names could not be normalized. Add patterns to TEAM_RULES.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;66;03m# =========================\u001b[39;00m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;66;03m# ---- Now continue simulator ----\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;66;03m# Make sure RS_contrib / RA_contrib exist BEFORE grouping\u001b[39;00m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;66;03m# =========================\u001b[39;00m\n\u001b[1;32m     83\u001b[0m LEAGUE_OPS \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.720\u001b[39m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Some team names could not be normalized. Add patterns to TEAM_RULES."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from difflib import get_close_matches\n",
    "\n",
    "# =========================\n",
    "# Load\n",
    "# =========================\n",
    "df = pd.read_csv(\"kbo_2026_prediction_dataset_adjusted.csv\")\n",
    "\n",
    "# =========================\n",
    "# Basic cleaning of raw team strings\n",
    "# =========================\n",
    "df[\"team_raw\"] = (\n",
    "    df[\"team\"]\n",
    "    .astype(str)\n",
    "    .str.replace(\"\\u200b\", \"\", regex=False)\n",
    "    .str.replace(\"\\xa0\", \" \", regex=False)\n",
    "    .str.strip()\n",
    ")\n",
    "\n",
    "# =========================\n",
    "# Canonical KBO team names\n",
    "# =========================\n",
    "CANON = [\n",
    "    \"Kiwoom Heroes\", \"SSG Landers\", \"LG Twins\", \"KIA Tigers\", \"KT Wiz\",\n",
    "    \"NC Dinos\", \"Doosan Bears\", \"Lotte Giants\", \"Samsung Lions\", \"Hanwha Eagles\"\n",
    "]\n",
    "\n",
    "# Keyword rules (Korean + common English)\n",
    "# Add more tokens if your raw file contains weird variants.\n",
    "TEAM_RULES = [\n",
    "    (\"Kiwoom Heroes\",   [r\"키움\", r\"히어로\", r\"kiwoom\", r\"heroes\"]),\n",
    "    (\"SSG Landers\",     [r\"ssg\", r\"랜더\", r\"landers\", r\"sk\\s*wyvern\", r\"wyvern\"]),\n",
    "    (\"LG Twins\",        [r\"\\blg\\b\", r\"트윈\", r\"twins\"]),\n",
    "    (\"KIA Tigers\",      [r\"\\bkia\\b\", r\"타이거\", r\"tigers\"]),\n",
    "    (\"KT Wiz\",          [r\"\\bkt\\b\", r\"위즈\", r\"wiz\"]),\n",
    "    (\"NC Dinos\",        [r\"\\bnc\\b\", r\"다이노\", r\"dinos\"]),\n",
    "    (\"Doosan Bears\",    [r\"두산\", r\"베어\", r\"doosan\", r\"bears\"]),\n",
    "    (\"Lotte Giants\",    [r\"롯데\", r\"자이언\", r\"lotte\", r\"giants\"]),\n",
    "    (\"Samsung Lions\",   [r\"삼성\", r\"라이온\", r\"samsung\", r\"lions\"]),\n",
    "    (\"Hanwha Eagles\",   [r\"한화\", r\"이글\", r\"hanwha\", r\"eagles\"]),\n",
    "]\n",
    "\n",
    "def normalize_team(s: str) -> str:\n",
    "    if s is None or s == \"\" or s.lower() == \"nan\":\n",
    "        return None\n",
    "\n",
    "    x = s.strip()\n",
    "    x_low = x.lower()\n",
    "\n",
    "    # 1) Keyword match (most reliable)\n",
    "    for canon, patterns in TEAM_RULES:\n",
    "        for pat in patterns:\n",
    "            if re.search(pat, x_low):\n",
    "                return canon\n",
    "\n",
    "    # 2) If it already looks like a canonical English team, keep it\n",
    "    close = get_close_matches(x, CANON, n=1, cutoff=0.80)\n",
    "    if close:\n",
    "        return close[0]\n",
    "\n",
    "    # 3) Could not normalize\n",
    "    return None\n",
    "\n",
    "df[\"team_norm\"] = df[\"team_raw\"].apply(normalize_team)\n",
    "\n",
    "# =========================\n",
    "# Diagnostics: see what failed normalization\n",
    "# =========================\n",
    "failed = df[df[\"team_norm\"].isna()][\"team_raw\"].value_counts()\n",
    "if len(failed) > 0:\n",
    "    print(\"\\n[TEAM NORMALIZATION FAILED FOR THESE RAW VALUES]\")\n",
    "    print(failed.head(30))\n",
    "\n",
    "# If normalization still fails for some values, STOP and add them to TEAM_RULES.\n",
    "assert df[\"team_norm\"].notna().all(), \"Some team names could not be normalized. Add patterns to TEAM_RULES.\"\n",
    "\n",
    "# =========================\n",
    "# ---- Now continue simulator ----\n",
    "# Make sure RS_contrib / RA_contrib exist BEFORE grouping\n",
    "# =========================\n",
    "LEAGUE_OPS = 0.720\n",
    "LEAGUE_ERA = 4.50\n",
    "LEAGUE_RPA = 0.115\n",
    "GAMES = 144\n",
    "PYTH_EXP = 1.83\n",
    "\n",
    "df[\"OPS_final\"] = df[\"OPS_adj\"].fillna(LEAGUE_OPS)\n",
    "df[\"ERA_final\"] = df[\"ERA_adj\"].fillna(LEAGUE_ERA)\n",
    "\n",
    "def assign_playing_time(row):\n",
    "    if row[\"section\"] == \"Batters\":\n",
    "        return 520 if row[\"role\"] in [\"1B\",\"2B\",\"3B\",\"SS\",\"LF\",\"CF\",\"RF\",\"C\",\"DH\"] else 220\n",
    "    else:\n",
    "        r = str(row[\"role\"]).lower()\n",
    "        if r == \"starter\":\n",
    "            return 160\n",
    "        if r in [\"closer\", \"setup\"]:\n",
    "            return 65\n",
    "        return 45\n",
    "\n",
    "df[\"PT\"] = df.apply(assign_playing_time, axis=1)\n",
    "\n",
    "df[\"RS_contrib\"] = np.where(\n",
    "    df[\"section\"] == \"Batters\",\n",
    "    df[\"PT\"] * (df[\"OPS_final\"] / LEAGUE_OPS) * LEAGUE_RPA,\n",
    "    0.0\n",
    ")\n",
    "\n",
    "df[\"RA_contrib\"] = np.where(\n",
    "    df[\"section\"] == \"Pitchers\",\n",
    "    df[\"PT\"] * df[\"ERA_final\"] / 9.0,\n",
    "    0.0\n",
    ")\n",
    "\n",
    "team_RS = df.groupby(\"team_norm\")[\"RS_contrib\"].sum()\n",
    "team_RA = df.groupby(\"team_norm\")[\"RA_contrib\"].sum()\n",
    "\n",
    "teams = pd.DataFrame({\n",
    "    \"team\": team_RS.index,\n",
    "    \"RS\": team_RS.values,\n",
    "    \"RA\": team_RA.reindex(team_RS.index).values\n",
    "})\n",
    "\n",
    "# Ensure exactly 10 teams\n",
    "assert teams.shape[0] == 10, f\"Expected 10 teams, got {teams.shape[0]}\"\n",
    "print(\"\\nTeams in simulation:\", teams[\"team\"].tolist())\n",
    "\n",
    "def pythag_wins(RS, RA):\n",
    "    return GAMES * (RS**PYTH_EXP / (RS**PYTH_EXP + RA**PYTH_EXP))\n",
    "\n",
    "teams[\"Expected_Wins\"] = teams.apply(lambda r: pythag_wins(r[\"RS\"], r[\"RA\"]), axis=1)\n",
    "print(\"\\n[PYTHAGOREAN EXPECTED WINS]\")\n",
    "print(teams.sort_values(\"Expected_Wins\", ascending=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "debc0442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['KIA Tigers', 'KT Wiz', 'LG Twins', 'NC Dinos', 'SSG Landers']\n",
      "team_norm\n",
      "None           106\n",
      "KT Wiz          22\n",
      "SSG Landers     22\n",
      "KIA Tigers      22\n",
      "NC Dinos        21\n",
      "LG Twins        21\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "ename": "RecursionError",
     "evalue": "maximum recursion depth exceeded while calling a Python object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRecursionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 39\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28mprint\u001b[39m(df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mteam_norm\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalue_counts(dropna\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m))\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# IMPORTANT: re-apply normalization after the function change\u001b[39;00m\n\u001b[0;32m---> 39\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mteam_norm\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mteam_raw\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnormalize_team\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# show any raw team strings that still fail\u001b[39;00m\n\u001b[1;32m     42\u001b[0m failed \u001b[38;5;241m=\u001b[39m df[df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mteam_norm\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39misna()][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mteam_raw\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalue_counts()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/torch_env/lib/python3.10/site-packages/pandas/core/series.py:4935\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m   4800\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4801\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4802\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4807\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4808\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4809\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4810\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4811\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4926\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4927\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   4928\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4929\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4930\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4931\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4932\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4933\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4934\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m-> 4935\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/torch_env/lib/python3.10/site-packages/pandas/core/apply.py:1422\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1419\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[1;32m   1421\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[0;32m-> 1422\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/torch_env/lib/python3.10/site-packages/pandas/core/apply.py:1502\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[1;32m   1499\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[1;32m   1500\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[1;32m   1501\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1502\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1503\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[1;32m   1504\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1507\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1508\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/torch_env/lib/python3.10/site-packages/pandas/core/base.py:925\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    922\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[1;32m    923\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[0;32m--> 925\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/torch_env/lib/python3.10/site-packages/pandas/core/algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[1;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[1;32m   1747\u001b[0m     )\n",
      "File \u001b[0;32mpandas/_libs/lib.pyx:2999\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "Cell \u001b[0;32mIn[16], line 11\u001b[0m, in \u001b[0;36mnormalize_team\u001b[0;34m(s)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mnormalize_team\u001b[39m(s: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m---> 11\u001b[0m     df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mteam_norm\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mteam_raw\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnormalize_team\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m s \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m s \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(s)\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnan\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     13\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/torch_env/lib/python3.10/site-packages/pandas/core/series.py:4935\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m   4800\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4801\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4802\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4807\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4808\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4809\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4810\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4811\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4926\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4927\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   4928\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4929\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4930\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4931\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4932\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4933\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4934\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m-> 4935\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/torch_env/lib/python3.10/site-packages/pandas/core/apply.py:1422\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1419\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[1;32m   1421\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[0;32m-> 1422\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/torch_env/lib/python3.10/site-packages/pandas/core/apply.py:1502\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[1;32m   1499\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[1;32m   1500\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[1;32m   1501\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1502\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1503\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[1;32m   1504\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1507\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1508\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/torch_env/lib/python3.10/site-packages/pandas/core/base.py:925\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    922\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[1;32m    923\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[0;32m--> 925\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/torch_env/lib/python3.10/site-packages/pandas/core/algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[1;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[1;32m   1747\u001b[0m     )\n",
      "File \u001b[0;32mpandas/_libs/lib.pyx:2999\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "Cell \u001b[0;32mIn[16], line 11\u001b[0m, in \u001b[0;36mnormalize_team\u001b[0;34m(s)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mnormalize_team\u001b[39m(s: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m---> 11\u001b[0m     df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mteam_norm\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mteam_raw\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnormalize_team\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m s \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m s \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(s)\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnan\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     13\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping similar frames: Series.apply at line 4935 (492 times), IndexOpsMixin._map_values at line 925 (491 times), SeriesApply.apply at line 1422 (491 times), SeriesApply.apply_standard at line 1502 (491 times), map_array at line 1743 (491 times), normalize_team at line 11 (491 times), pandas._libs.lib.map_infer at line 2999 (491 times)]\u001b[0m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/torch_env/lib/python3.10/site-packages/pandas/core/apply.py:1422\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1419\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[1;32m   1421\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[0;32m-> 1422\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/torch_env/lib/python3.10/site-packages/pandas/core/apply.py:1502\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[1;32m   1499\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[1;32m   1500\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[1;32m   1501\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1502\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1503\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[1;32m   1504\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1507\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1508\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/torch_env/lib/python3.10/site-packages/pandas/core/base.py:925\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    922\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[1;32m    923\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[0;32m--> 925\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/torch_env/lib/python3.10/site-packages/pandas/core/algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[1;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[1;32m   1747\u001b[0m     )\n",
      "File \u001b[0;32mpandas/_libs/lib.pyx:2999\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "Cell \u001b[0;32mIn[16], line 11\u001b[0m, in \u001b[0;36mnormalize_team\u001b[0;34m(s)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mnormalize_team\u001b[39m(s: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m---> 11\u001b[0m     df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mteam_norm\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mteam_raw\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnormalize_team\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m s \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m s \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(s)\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnan\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     13\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/torch_env/lib/python3.10/site-packages/pandas/core/series.py:4935\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m   4800\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4801\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4802\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4807\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4808\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4809\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4810\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4811\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4926\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4927\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   4928\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4929\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4930\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4931\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4932\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4933\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4934\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m-> 4935\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/torch_env/lib/python3.10/site-packages/pandas/core/apply.py:1407\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1404\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mapply\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   1405\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\n\u001b[0;32m-> 1407\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1408\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_empty_result()\n\u001b[1;32m   1410\u001b[0m     \u001b[38;5;66;03m# dispatch to handle list-like or dict-like\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/torch_env/lib/python3.10/site-packages/pandas/core/series.py:918\u001b[0m, in \u001b[0;36mSeries.__len__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__len__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[1;32m    915\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    916\u001b[0m \u001b[38;5;124;03m    Return the length of the Series.\u001b[39;00m\n\u001b[1;32m    917\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/torch_env/lib/python3.10/site-packages/pandas/core/internals/base.py:76\u001b[0m, in \u001b[0;36mDataManager.__len__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__len__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[0;32m---> 76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/torch_env/lib/python3.10/site-packages/pandas/core/indexes/range.py:1003\u001b[0m, in \u001b[0;36mRangeIndex.__len__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    999\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__len__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[1;32m   1000\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1001\u001b[0m \u001b[38;5;124;03m    return the length of the RangeIndex\u001b[39;00m\n\u001b[1;32m   1002\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1003\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_range\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRecursionError\u001b[0m: maximum recursion depth exceeded while calling a Python object"
     ]
    }
   ],
   "source": [
    "# 0) Direct map for garbled encodings (from your diagnostic output)\n",
    "GARBLED_MAP = {\n",
    "    \"Ű\": \"Kiwoom Heroes\",\n",
    "    \"λ꺣\": \"Lotte Giants\",\n",
    "    \"Ｚ̿\": \"Samsung Lions\",\n",
    "    \"ȭ̱۽\": \"Doosan Bears\",\n",
    "    \"Ե ̾\": \"Hanwha Eagles\",\n",
    "}\n",
    "\n",
    "def normalize_team(s: str) -> str:\n",
    "    df[\"team_norm\"] = df[\"team_raw\"].apply(normalize_team)\n",
    "    if s is None or s == \"\" or str(s).lower() == \"nan\":\n",
    "        return None\n",
    "\n",
    "    x = str(s).strip()\n",
    "    x_low = x.lower()\n",
    "\n",
    "    # 0) Direct map (most reliable for corrupted strings)\n",
    "    if x in GARBLED_MAP:\n",
    "        return GARBLED_MAP[x]\n",
    "\n",
    "    # 1) Keyword match\n",
    "    for canon, patterns in TEAM_RULES:\n",
    "        for pat in patterns:\n",
    "            if re.search(pat, x_low):\n",
    "                return canon\n",
    "\n",
    "    # 2) Fuzzy match to canonical English\n",
    "    close = get_close_matches(x, CANON, n=1, cutoff=0.80)\n",
    "    if close:\n",
    "        return close[0]\n",
    "\n",
    "    return None\n",
    "\n",
    "print(sorted([x for x in df[\"team_norm\"].unique() if isinstance(x, str)]))\n",
    "print(df[\"team_norm\"].value_counts(dropna=False))\n",
    "\n",
    "# IMPORTANT: re-apply normalization after the function change\n",
    "df[\"team_norm\"] = df[\"team_raw\"].apply(normalize_team)\n",
    "\n",
    "# show any raw team strings that still fail\n",
    "failed = df[df[\"team_norm\"].isna()][\"team_raw\"].value_counts()\n",
    "print(\"[STILL FAILING RAW TEAM STRINGS]\")\n",
    "print(failed)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f4bdf646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[FAILED RAW TEAM VALUES]\n",
      "Series([], Name: count, dtype: int64)\n",
      "\n",
      "[TEAM NORM COUNTS]\n",
      "team_norm\n",
      "Hanwha Eagles    23\n",
      "KT Wiz           22\n",
      "Doosan Bears     22\n",
      "SSG Landers      22\n",
      "Kiwoom Heroes    22\n",
      "Lotte Giants     22\n",
      "KIA Tigers       22\n",
      "NC Dinos         21\n",
      "LG Twins         21\n",
      "Samsung Lions    17\n",
      "Name: count, dtype: int64\n",
      "\n",
      "OK: 10 teams normalized: ['Doosan Bears', 'Hanwha Eagles', 'KIA Tigers', 'KT Wiz', 'Kiwoom Heroes', 'LG Twins', 'Lotte Giants', 'NC Dinos', 'SSG Landers', 'Samsung Lions']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import unicodedata\n",
    "\n",
    "df = pd.read_csv(\"kbo_2026_prediction_dataset_adjusted.csv\")\n",
    "\n",
    "# 1) Clean raw team strings\n",
    "def clean_text(s: str) -> str:\n",
    "    s = \"\" if s is None else str(s)\n",
    "    # Normalize Unicode (fixes full-width chars, etc.)\n",
    "    s = unicodedata.normalize(\"NFKC\", s)\n",
    "    # Remove zero-width and non-breaking spaces\n",
    "    s = s.replace(\"\\u200b\", \"\").replace(\"\\xa0\", \" \")\n",
    "    # Strip\n",
    "    return s.strip()\n",
    "\n",
    "df[\"team_raw\"] = df[\"team\"].apply(clean_text)\n",
    "\n",
    "# 2) Canonicalize \"keys\" by removing ALL whitespace + invisible marks\n",
    "def canonical_key(s: str) -> str:\n",
    "    s = clean_text(s)\n",
    "    # Remove all whitespace\n",
    "    s = re.sub(r\"\\s+\", \"\", s)\n",
    "    # Remove Unicode \"format\" and \"combining mark\" characters\n",
    "    s = \"\".join(ch for ch in s if unicodedata.category(ch) not in (\"Cf\", \"Mn\"))\n",
    "    return s\n",
    "\n",
    "# 3) Direct mapping for the 5 garbled values you observed\n",
    "GARBLED_MAP = {\n",
    "    \"Ű\": \"Kiwoom Heroes\",\n",
    "    \"λ꺣\": \"Lotte Giants\",\n",
    "    \"Ｚ̿\": \"Samsung Lions\",\n",
    "    \"ȭ̱۽\": \"Doosan Bears\",\n",
    "    \"Ե ̾\": \"Hanwha Eagles\",\n",
    "}\n",
    "\n",
    "# Canonicalize the garbled keys too (THIS is the key fix)\n",
    "GARBLED_MAP_CANON = {canonical_key(k): v for k, v in GARBLED_MAP.items()}\n",
    "\n",
    "# 4) Keyword rules for normal (non-garbled) strings\n",
    "TEAM_RULES = [\n",
    "    (\"Kiwoom Heroes\",   [r\"키움\", r\"히어로\", r\"kiwoom\", r\"heroes\"]),\n",
    "    (\"SSG Landers\",     [r\"ssg\", r\"랜더\", r\"landers\", r\"wyvern\", r\"sk\\s*wyvern\"]),\n",
    "    (\"LG Twins\",        [r\"\\blg\\b\", r\"트윈\", r\"twins\"]),\n",
    "    (\"KIA Tigers\",      [r\"\\bkia\\b\", r\"타이거\", r\"tigers\"]),\n",
    "    (\"KT Wiz\",          [r\"\\bkt\\b\", r\"위즈\", r\"wiz\"]),\n",
    "    (\"NC Dinos\",        [r\"\\bnc\\b\", r\"다이노\", r\"dinos\"]),\n",
    "    (\"Doosan Bears\",    [r\"두산\", r\"베어\", r\"doosan\", r\"bears\"]),\n",
    "    (\"Lotte Giants\",    [r\"롯데\", r\"자이언\", r\"lotte\", r\"giants\"]),\n",
    "    (\"Samsung Lions\",   [r\"삼성\", r\"라이온\", r\"samsung\", r\"lions\"]),\n",
    "    (\"Hanwha Eagles\",   [r\"한화\", r\"이글\", r\"hanwha\", r\"eagles\"]),\n",
    "]\n",
    "\n",
    "CANON_TEAMS = [\n",
    "    \"Kiwoom Heroes\", \"SSG Landers\", \"LG Twins\", \"KIA Tigers\", \"KT Wiz\",\n",
    "    \"NC Dinos\", \"Doosan Bears\", \"Lotte Giants\", \"Samsung Lions\", \"Hanwha Eagles\"\n",
    "]\n",
    "\n",
    "def normalize_team(s: str) -> str:\n",
    "    if s is None:\n",
    "        return None\n",
    "    x = clean_text(s)\n",
    "    if x == \"\" or x.lower() == \"nan\":\n",
    "        return None\n",
    "\n",
    "    # A) Direct garbled-key mapping (robust)\n",
    "    k = canonical_key(x)\n",
    "    if k in GARBLED_MAP_CANON:\n",
    "        return GARBLED_MAP_CANON[k]\n",
    "\n",
    "    # B) Keyword mapping\n",
    "    x_low = x.lower()\n",
    "    for canon, patterns in TEAM_RULES:\n",
    "        for pat in patterns:\n",
    "            if re.search(pat, x_low):\n",
    "                return canon\n",
    "\n",
    "    # C) If already canonical english, keep it\n",
    "    if x in CANON_TEAMS:\n",
    "        return x\n",
    "\n",
    "    return None\n",
    "\n",
    "df[\"team_norm\"] = df[\"team_raw\"].apply(normalize_team)\n",
    "\n",
    "# Diagnostics\n",
    "failed = df[df[\"team_norm\"].isna()][\"team_raw\"].value_counts()\n",
    "print(\"\\n[FAILED RAW TEAM VALUES]\")\n",
    "print(failed)\n",
    "\n",
    "print(\"\\n[TEAM NORM COUNTS]\")\n",
    "print(df[\"team_norm\"].value_counts(dropna=False))\n",
    "\n",
    "# Hard stop if still failing\n",
    "assert df[\"team_norm\"].notna().all(), \"Still have unmapped team strings. See FAILED RAW TEAM VALUES above.\"\n",
    "assert df[\"team_norm\"].nunique() == 10, f\"Expected 10 teams, got {df['team_norm'].nunique()}\"\n",
    "print(\"\\nOK: 10 teams normalized:\", sorted(df[\"team_norm\"].unique()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cb9fa7ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Sanity] Total mean wins: 719.9999999999998 (target 720)\n",
      "[Teams] ['Samsung Lions', 'SSG Landers', 'Lotte Giants', 'LG Twins', 'Doosan Bears', 'KIA Tigers', 'NC Dinos', 'KT Wiz', 'Hanwha Eagles', 'Kiwoom Heroes']\n",
      "\n",
      "Saved: kbo_2026_season_simulation_results_final.csv\n",
      "            team          RS          RA  Expected_Wins  Wins_mean   Wins_p10  \\\n",
      "0  Samsung Lions  508.181806  465.714444      91.556810  91.389554  83.241070   \n",
      "1    SSG Landers  538.647222  525.950000      86.650616  86.622100  78.421670   \n",
      "2   Lotte Giants  531.245694  522.615556      86.070721  85.941174  77.860178   \n",
      "3       LG Twins  488.299583  494.544444      83.813989  83.904537  75.864208   \n",
      "4   Doosan Bears  537.494028  621.694444      73.574205  73.590036  65.815352   \n",
      "5     KIA Tigers  509.945394  636.788889      67.797609  67.677369  60.038017   \n",
      "6       NC Dinos  482.099167  614.204444      66.310550  66.331204  58.693327   \n",
      "7         KT Wiz  424.817028  556.407778      64.277679  64.382268  56.646861   \n",
      "8  Hanwha Eagles  519.426250  694.538889      62.774089  62.800504  55.213214   \n",
      "9  Kiwoom Heroes  482.429217  965.894444      37.173733  37.361253  31.783970   \n",
      "\n",
      "    Wins_p90  \n",
      "0  99.600289  \n",
      "1  94.876365  \n",
      "2  94.217832  \n",
      "3  92.152600  \n",
      "4  81.687766  \n",
      "5  75.419224  \n",
      "6  74.332728  \n",
      "7  72.324382  \n",
      "8  70.599579  \n",
      "9  43.093842  \n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# KBO 2026 SEASON SIMULATOR (FINAL)\n",
    "# - Robust team normalization\n",
    "# - Missing stat regression\n",
    "# - Team RS/RA aggregation\n",
    "# - Pythagorean win%\n",
    "# - Monte Carlo\n",
    "# - Enforces league zero-sum wins (total = 720)\n",
    "# ============================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import unicodedata\n",
    "\n",
    "INPUT_CSV  = \"kbo_2026_prediction_dataset_adjusted.csv\"\n",
    "OUTPUT_CSV = \"kbo_2026_season_simulation_results_final.csv\"\n",
    "\n",
    "# League constants (baseline)\n",
    "LEAGUE_OPS = 0.720\n",
    "LEAGUE_ERA = 4.50\n",
    "LEAGUE_RPA = 0.115\n",
    "GAMES = 144\n",
    "N_TEAMS = 10\n",
    "TOTAL_WINS_LEAGUE = (GAMES * N_TEAMS) / 2  # 720\n",
    "PYTH_EXP = 1.83\n",
    "\n",
    "# Monte Carlo\n",
    "N_SIM = 5000\n",
    "SIGMA_RS = 0.05\n",
    "SIGMA_RA = 0.07\n",
    "RNG_SEED = 42\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Load\n",
    "# -----------------------------\n",
    "df = pd.read_csv(INPUT_CSV)\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Robust team normalization\n",
    "# -----------------------------\n",
    "def clean_text(s: str) -> str:\n",
    "    s = \"\" if s is None else str(s)\n",
    "    s = unicodedata.normalize(\"NFKC\", s)\n",
    "    s = s.replace(\"\\u200b\", \"\").replace(\"\\xa0\", \" \")\n",
    "    return s.strip()\n",
    "\n",
    "def canonical_key(s: str) -> str:\n",
    "    s = clean_text(s)\n",
    "    s = re.sub(r\"\\s+\", \"\", s)\n",
    "    s = \"\".join(ch for ch in s if unicodedata.category(ch) not in (\"Cf\", \"Mn\"))\n",
    "    return s\n",
    "\n",
    "GARBLED_MAP = {\n",
    "    \"Ű\": \"Kiwoom Heroes\",\n",
    "    \"λ꺣\": \"Lotte Giants\",\n",
    "    \"Ｚ̿\": \"Samsung Lions\",\n",
    "    \"ȭ̱۽\": \"Doosan Bears\",\n",
    "    \"Ե ̾\": \"Hanwha Eagles\",\n",
    "}\n",
    "GARBLED_MAP_CANON = {canonical_key(k): v for k, v in GARBLED_MAP.items()}\n",
    "\n",
    "TEAM_RULES = [\n",
    "    (\"Kiwoom Heroes\",   [r\"키움\", r\"히어로\", r\"kiwoom\", r\"heroes\"]),\n",
    "    (\"SSG Landers\",     [r\"ssg\", r\"랜더\", r\"landers\", r\"wyvern\", r\"sk\\s*wyvern\"]),\n",
    "    (\"LG Twins\",        [r\"\\blg\\b\", r\"트윈\", r\"twins\"]),\n",
    "    (\"KIA Tigers\",      [r\"\\bkia\\b\", r\"타이거\", r\"tigers\"]),\n",
    "    (\"KT Wiz\",          [r\"\\bkt\\b\", r\"위즈\", r\"wiz\"]),\n",
    "    (\"NC Dinos\",        [r\"\\bnc\\b\", r\"다이노\", r\"dinos\"]),\n",
    "    (\"Doosan Bears\",    [r\"두산\", r\"베어\", r\"doosan\", r\"bears\"]),\n",
    "    (\"Lotte Giants\",    [r\"롯데\", r\"자이언\", r\"lotte\", r\"giants\"]),\n",
    "    (\"Samsung Lions\",   [r\"삼성\", r\"라이온\", r\"samsung\", r\"lions\"]),\n",
    "    (\"Hanwha Eagles\",   [r\"한화\", r\"이글\", r\"hanwha\", r\"eagles\"]),\n",
    "]\n",
    "CANON_TEAMS = [\n",
    "    \"Kiwoom Heroes\",\"SSG Landers\",\"LG Twins\",\"KIA Tigers\",\"KT Wiz\",\n",
    "    \"NC Dinos\",\"Doosan Bears\",\"Lotte Giants\",\"Samsung Lions\",\"Hanwha Eagles\"\n",
    "]\n",
    "\n",
    "def normalize_team(s: str) -> str:\n",
    "    x = clean_text(s)\n",
    "    if x == \"\" or x.lower() == \"nan\":\n",
    "        return None\n",
    "\n",
    "    k = canonical_key(x)\n",
    "    if k in GARBLED_MAP_CANON:\n",
    "        return GARBLED_MAP_CANON[k]\n",
    "\n",
    "    x_low = x.lower()\n",
    "    for canon, pats in TEAM_RULES:\n",
    "        for pat in pats:\n",
    "            if re.search(pat, x_low):\n",
    "                return canon\n",
    "\n",
    "    if x in CANON_TEAMS:\n",
    "        return x\n",
    "\n",
    "    return None\n",
    "\n",
    "df[\"team_raw\"] = df[\"team\"].apply(clean_text)\n",
    "df[\"team_norm\"] = df[\"team_raw\"].apply(normalize_team)\n",
    "\n",
    "failed = df[df[\"team_norm\"].isna()][\"team_raw\"].value_counts()\n",
    "if len(failed) > 0:\n",
    "    print(\"\\n[TEAM NORMALIZATION FAILED FOR THESE RAW VALUES]\")\n",
    "    print(failed)\n",
    "assert df[\"team_norm\"].notna().all(), \"Unmapped team strings remain.\"\n",
    "assert df[\"team_norm\"].nunique() == 10, f\"Expected 10 teams, got {df['team_norm'].nunique()}\"\n",
    "\n",
    "# -----------------------------\n",
    "# 3) Regress missing stats\n",
    "# -----------------------------\n",
    "df[\"OPS_final\"] = df[\"OPS_adj\"].fillna(LEAGUE_OPS)\n",
    "df[\"ERA_final\"] = df[\"ERA_adj\"].fillna(LEAGUE_ERA)\n",
    "\n",
    "# -----------------------------\n",
    "# 4) Playing time baseline\n",
    "# -----------------------------\n",
    "STARTER_POS = {\"1B\",\"2B\",\"3B\",\"SS\",\"LF\",\"CF\",\"RF\",\"C\",\"DH\"}\n",
    "\n",
    "def assign_playing_time(row):\n",
    "    if row[\"section\"] == \"Batters\":\n",
    "        return 520 if str(row[\"role\"]) in STARTER_POS else 220  # PA\n",
    "    else:\n",
    "        r = str(row[\"role\"]).lower()\n",
    "        if r == \"starter\":\n",
    "            return 160  # IP\n",
    "        if r in {\"closer\",\"setup\"}:\n",
    "            return 65\n",
    "        return 45\n",
    "\n",
    "df[\"PT\"] = df.apply(assign_playing_time, axis=1)\n",
    "\n",
    "# -----------------------------\n",
    "# 5) Team RS/RA\n",
    "# -----------------------------\n",
    "df[\"RS_contrib\"] = np.where(\n",
    "    df[\"section\"] == \"Batters\",\n",
    "    df[\"PT\"] * (df[\"OPS_final\"] / LEAGUE_OPS) * LEAGUE_RPA,\n",
    "    0.0\n",
    ")\n",
    "\n",
    "df[\"RA_contrib\"] = np.where(\n",
    "    df[\"section\"] == \"Pitchers\",\n",
    "    df[\"PT\"] * df[\"ERA_final\"] / 9.0,\n",
    "    0.0\n",
    ")\n",
    "\n",
    "team_RS = df.groupby(\"team_norm\")[\"RS_contrib\"].sum()\n",
    "team_RA = df.groupby(\"team_norm\")[\"RA_contrib\"].sum()\n",
    "\n",
    "teams = pd.DataFrame({\n",
    "    \"team\": team_RS.index.to_list(),\n",
    "    \"RS\": team_RS.values,\n",
    "    \"RA\": team_RA.reindex(team_RS.index).values\n",
    "})\n",
    "\n",
    "assert len(teams) == 10\n",
    "\n",
    "# -----------------------------\n",
    "# 6) Pythagorean win% -> wins (NOT zero-sum yet)\n",
    "# -----------------------------\n",
    "def pythag_winpct(RS, RA, exp=PYTH_EXP):\n",
    "    RS = np.asarray(RS, dtype=float)\n",
    "    RA = np.asarray(RA, dtype=float)\n",
    "    return (RS**exp) / (RS**exp + RA**exp)\n",
    "\n",
    "teams[\"WinPct_raw\"] = pythag_winpct(teams[\"RS\"], teams[\"RA\"])\n",
    "teams[\"Wins_raw\"] = teams[\"WinPct_raw\"] * GAMES\n",
    "\n",
    "# Enforce zero-sum league wins by scaling to 720\n",
    "scale = TOTAL_WINS_LEAGUE / teams[\"Wins_raw\"].sum()\n",
    "teams[\"Expected_Wins\"] = teams[\"Wins_raw\"] * scale\n",
    "\n",
    "# -----------------------------\n",
    "# 7) Monte Carlo (also zero-sum per simulation)\n",
    "# -----------------------------\n",
    "rng = np.random.default_rng(RNG_SEED)\n",
    "sim_wins = np.zeros((N_SIM, len(teams)), dtype=float)\n",
    "\n",
    "for i in range(N_SIM):\n",
    "    RS_sim = teams[\"RS\"].values * rng.normal(1.0, SIGMA_RS, size=len(teams))\n",
    "    RA_sim = teams[\"RA\"].values * rng.normal(1.0, SIGMA_RA, size=len(teams))\n",
    "    RS_sim = np.clip(RS_sim, 1e-6, None)\n",
    "    RA_sim = np.clip(RA_sim, 1e-6, None)\n",
    "\n",
    "    winpct = pythag_winpct(RS_sim, RA_sim)\n",
    "    wins = winpct * GAMES\n",
    "\n",
    "    # enforce total wins = 720 in this simulation\n",
    "    wins *= (TOTAL_WINS_LEAGUE / wins.sum())\n",
    "    sim_wins[i, :] = wins\n",
    "\n",
    "sim_df = pd.DataFrame(sim_wins, columns=teams[\"team\"].values)\n",
    "\n",
    "summary = pd.DataFrame({\n",
    "    \"team\": teams[\"team\"].values,\n",
    "    \"RS\": teams[\"RS\"].values,\n",
    "    \"RA\": teams[\"RA\"].values,\n",
    "    \"Expected_Wins\": teams[\"Expected_Wins\"].values,\n",
    "    \"Wins_mean\": sim_df.mean().values,\n",
    "    \"Wins_p10\": sim_df.quantile(0.10).values,\n",
    "    \"Wins_p90\": sim_df.quantile(0.90).values,\n",
    "}).sort_values(\"Wins_mean\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(\"\\n[Sanity] Total mean wins:\", float(summary[\"Wins_mean\"].sum()), \"(target 720)\")\n",
    "print(\"[Teams]\", summary[\"team\"].tolist())\n",
    "\n",
    "summary.to_csv(OUTPUT_CSV, index=False)\n",
    "print(\"\\nSaved:\", OUTPUT_CSV)\n",
    "print(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "af34671b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# KBO 2026 SEASON SIMULATOR + TRADE SCENARIO FUNCTION\n",
    "# ============================================================\n",
    "# - Loads kbo_2026_prediction_dataset_adjusted.csv\n",
    "# - Normalizes teams robustly\n",
    "# - Builds RS/RA and win distribution (zero-sum 720)\n",
    "# - Adds: trade_players(p1, p2) -> preview -> confirm -> swap -> rerun -> Δ wins\n",
    "# ============================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import unicodedata\n",
    "\n",
    "# -----------------------------\n",
    "# CONFIG\n",
    "# -----------------------------\n",
    "INPUT_CSV = \"kbo_2026_prediction_dataset_adjusted.csv\"\n",
    "\n",
    "# League constants (baseline)\n",
    "LEAGUE_OPS = 0.720\n",
    "LEAGUE_ERA = 4.50\n",
    "LEAGUE_RPA = 0.115\n",
    "GAMES = 144\n",
    "N_TEAMS = 10\n",
    "TOTAL_WINS_LEAGUE = (GAMES * N_TEAMS) / 2  # 720\n",
    "PYTH_EXP = 1.83\n",
    "\n",
    "# Monte Carlo\n",
    "N_SIM = 3000\n",
    "SIGMA_RS = 0.05\n",
    "SIGMA_RA = 0.07\n",
    "RNG_SEED = 42\n",
    "\n",
    "# -----------------------------\n",
    "# TEAM NORMALIZATION (robust)\n",
    "# -----------------------------\n",
    "def clean_text(s: str) -> str:\n",
    "    s = \"\" if s is None else str(s)\n",
    "    s = unicodedata.normalize(\"NFKC\", s)\n",
    "    s = s.replace(\"\\u200b\", \"\").replace(\"\\xa0\", \" \")\n",
    "    return s.strip()\n",
    "\n",
    "def canonical_key(s: str) -> str:\n",
    "    s = clean_text(s)\n",
    "    s = re.sub(r\"\\s+\", \"\", s)\n",
    "    s = \"\".join(ch for ch in s if unicodedata.category(ch) not in (\"Cf\", \"Mn\"))\n",
    "    return s\n",
    "\n",
    "GARBLED_MAP = {\n",
    "    \"Ű\": \"Kiwoom Heroes\",\n",
    "    \"λ꺣\": \"Lotte Giants\",\n",
    "    \"Ｚ̿\": \"Samsung Lions\",\n",
    "    \"ȭ̱۽\": \"Doosan Bears\",\n",
    "    \"Ե ̾\": \"Hanwha Eagles\",\n",
    "}\n",
    "GARBLED_MAP_CANON = {canonical_key(k): v for k, v in GARBLED_MAP.items()}\n",
    "\n",
    "TEAM_RULES = [\n",
    "    (\"Kiwoom Heroes\",   [r\"키움\", r\"히어로\", r\"kiwoom\", r\"heroes\"]),\n",
    "    (\"SSG Landers\",     [r\"ssg\", r\"랜더\", r\"landers\", r\"wyvern\", r\"sk\\s*wyvern\"]),\n",
    "    (\"LG Twins\",        [r\"\\blg\\b\", r\"트윈\", r\"twins\"]),\n",
    "    (\"KIA Tigers\",      [r\"\\bkia\\b\", r\"타이거\", r\"tigers\"]),\n",
    "    (\"KT Wiz\",          [r\"\\bkt\\b\", r\"위즈\", r\"wiz\"]),\n",
    "    (\"NC Dinos\",        [r\"\\bnc\\b\", r\"다이노\", r\"dinos\"]),\n",
    "    (\"Doosan Bears\",    [r\"두산\", r\"베어\", r\"doosan\", r\"bears\"]),\n",
    "    (\"Lotte Giants\",    [r\"롯데\", r\"자이언\", r\"lotte\", r\"giants\"]),\n",
    "    (\"Samsung Lions\",   [r\"삼성\", r\"라이온\", r\"samsung\", r\"lions\"]),\n",
    "    (\"Hanwha Eagles\",   [r\"한화\", r\"이글\", r\"hanwha\", r\"eagles\"]),\n",
    "]\n",
    "CANON_TEAMS = [\n",
    "    \"Kiwoom Heroes\",\"SSG Landers\",\"LG Twins\",\"KIA Tigers\",\"KT Wiz\",\n",
    "    \"NC Dinos\",\"Doosan Bears\",\"Lotte Giants\",\"Samsung Lions\",\"Hanwha Eagles\"\n",
    "]\n",
    "\n",
    "def normalize_team(s: str) -> str:\n",
    "    x = clean_text(s)\n",
    "    if x == \"\" or x.lower() == \"nan\":\n",
    "        return None\n",
    "\n",
    "    k = canonical_key(x)\n",
    "    if k in GARBLED_MAP_CANON:\n",
    "        return GARBLED_MAP_CANON[k]\n",
    "\n",
    "    x_low = x.lower()\n",
    "    for canon, pats in TEAM_RULES:\n",
    "        for pat in pats:\n",
    "            if re.search(pat, x_low):\n",
    "                return canon\n",
    "\n",
    "    if x in CANON_TEAMS:\n",
    "        return x\n",
    "\n",
    "    return None\n",
    "\n",
    "# -----------------------------\n",
    "# LOAD + PREP DATA\n",
    "# -----------------------------\n",
    "df0 = pd.read_csv(INPUT_CSV)\n",
    "\n",
    "# Normalize teams\n",
    "df0[\"team_raw\"] = df0[\"team\"].apply(clean_text)\n",
    "df0[\"team_norm\"] = df0[\"team_raw\"].apply(normalize_team)\n",
    "\n",
    "failed = df0[df0[\"team_norm\"].isna()][\"team_raw\"].value_counts()\n",
    "if len(failed) > 0:\n",
    "    print(\"\\n[TEAM NORMALIZATION FAILED FOR THESE RAW VALUES]\")\n",
    "    print(failed)\n",
    "assert df0[\"team_norm\"].notna().all(), \"Unmapped team strings remain.\"\n",
    "assert df0[\"team_norm\"].nunique() == 10, f\"Expected 10 teams, got {df0['team_norm'].nunique()}\"\n",
    "\n",
    "# Regress missing stats\n",
    "df0[\"OPS_final\"] = df0.get(\"OPS_adj\", pd.Series([np.nan]*len(df0))).fillna(LEAGUE_OPS)\n",
    "df0[\"ERA_final\"] = df0.get(\"ERA_adj\", pd.Series([np.nan]*len(df0))).fillna(LEAGUE_ERA)\n",
    "\n",
    "# Baseline playing time\n",
    "STARTER_POS = {\"1B\",\"2B\",\"3B\",\"SS\",\"LF\",\"CF\",\"RF\",\"C\",\"DH\"}\n",
    "def assign_playing_time(row):\n",
    "    if row[\"section\"] == \"Batters\":\n",
    "        return 520 if str(row[\"role\"]) in STARTER_POS else 220\n",
    "    r = str(row[\"role\"]).lower()\n",
    "    if r == \"starter\":\n",
    "        return 160\n",
    "    if r in {\"closer\",\"setup\"}:\n",
    "        return 65\n",
    "    return 45\n",
    "\n",
    "df0[\"PT\"] = df0.apply(assign_playing_time, axis=1)\n",
    "\n",
    "# -----------------------------\n",
    "# CORE SIMULATOR\n",
    "# -----------------------------\n",
    "def pythag_winpct(RS, RA, exp=PYTH_EXP):\n",
    "    RS = np.asarray(RS, dtype=float)\n",
    "    RA = np.asarray(RA, dtype=float)\n",
    "    return (RS**exp) / (RS**exp + RA**exp)\n",
    "\n",
    "def simulate_season(df_in: pd.DataFrame, n_sim=N_SIM, seed=RNG_SEED):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      summary: team-level dataframe with RS, RA, Expected_Wins, Wins_mean, Wins_p10, Wins_p90\n",
    "    \"\"\"\n",
    "    df = df_in.copy()\n",
    "\n",
    "    # Contributions\n",
    "    df[\"RS_contrib\"] = np.where(\n",
    "        df[\"section\"] == \"Batters\",\n",
    "        df[\"PT\"] * (df[\"OPS_final\"] / LEAGUE_OPS) * LEAGUE_RPA,\n",
    "        0.0\n",
    "    )\n",
    "    df[\"RA_contrib\"] = np.where(\n",
    "        df[\"section\"] == \"Pitchers\",\n",
    "        df[\"PT\"] * df[\"ERA_final\"] / 9.0,\n",
    "        0.0\n",
    "    )\n",
    "\n",
    "    team_RS = df.groupby(\"team_norm\")[\"RS_contrib\"].sum()\n",
    "    team_RA = df.groupby(\"team_norm\")[\"RA_contrib\"].sum()\n",
    "\n",
    "    teams = pd.DataFrame({\n",
    "        \"team\": team_RS.index.to_list(),\n",
    "        \"RS\": team_RS.values,\n",
    "        \"RA\": team_RA.reindex(team_RS.index).values\n",
    "    })\n",
    "    assert len(teams) == 10, f\"Expected 10 teams, got {len(teams)}\"\n",
    "\n",
    "    # Expected wins (scaled to league total 720)\n",
    "    winpct = pythag_winpct(teams[\"RS\"], teams[\"RA\"])\n",
    "    wins_raw = winpct * GAMES\n",
    "    scale = TOTAL_WINS_LEAGUE / wins_raw.sum()\n",
    "    teams[\"Expected_Wins\"] = wins_raw * scale\n",
    "\n",
    "    # Monte Carlo (also scaled to 720 each sim)\n",
    "    rng = np.random.default_rng(seed)\n",
    "    sim_wins = np.zeros((n_sim, len(teams)), dtype=float)\n",
    "\n",
    "    for i in range(n_sim):\n",
    "        RS_sim = teams[\"RS\"].values * rng.normal(1.0, SIGMA_RS, size=len(teams))\n",
    "        RA_sim = teams[\"RA\"].values * rng.normal(1.0, SIGMA_RA, size=len(teams))\n",
    "        RS_sim = np.clip(RS_sim, 1e-6, None)\n",
    "        RA_sim = np.clip(RA_sim, 1e-6, None)\n",
    "\n",
    "        winpct_i = pythag_winpct(RS_sim, RA_sim)\n",
    "        wins_i = winpct_i * GAMES\n",
    "        wins_i *= (TOTAL_WINS_LEAGUE / wins_i.sum())\n",
    "        sim_wins[i, :] = wins_i\n",
    "\n",
    "    sim_df = pd.DataFrame(sim_wins, columns=teams[\"team\"].values)\n",
    "\n",
    "    summary = pd.DataFrame({\n",
    "        \"team\": teams[\"team\"].values,\n",
    "        \"RS\": teams[\"RS\"].values,\n",
    "        \"RA\": teams[\"RA\"].values,\n",
    "        \"Expected_Wins\": teams[\"Expected_Wins\"].values,\n",
    "        \"Wins_mean\": sim_df.mean().values,\n",
    "        \"Wins_p10\": sim_df.quantile(0.10).values,\n",
    "        \"Wins_p90\": sim_df.quantile(0.90).values,\n",
    "    }).sort_values(\"Wins_mean\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "    return summary\n",
    "\n",
    "# Baseline results (optional)\n",
    "baseline_summary = simulate_season(df0)\n",
    "\n",
    "# -----------------------------\n",
    "# TRADE FUNCTION\n",
    "# -----------------------------\n",
    "def _find_player_rows(df: pd.DataFrame, player_name: str):\n",
    "    \"\"\"\n",
    "    Tries to match player by exact name, then case-insensitive contains.\n",
    "    Returns a dataframe of matching rows.\n",
    "    \"\"\"\n",
    "    name_col = \"player\" if \"player\" in df.columns else (\"Name\" if \"Name\" in df.columns else None)\n",
    "    if name_col is None:\n",
    "        raise ValueError(\"No player name column found. Expected 'player' or 'Name'.\")\n",
    "\n",
    "    # exact match first\n",
    "    exact = df[df[name_col].astype(str) == str(player_name)]\n",
    "    if len(exact) > 0:\n",
    "        return exact, name_col\n",
    "\n",
    "    # contains match\n",
    "    pat = re.escape(str(player_name).strip())\n",
    "    contains = df[df[name_col].astype(str).str.contains(pat, case=False, na=False)]\n",
    "    return contains, name_col\n",
    "\n",
    "def trade_players(df_base: pd.DataFrame,\n",
    "                  player1: str,\n",
    "                  player2: str,\n",
    "                  confirm: bool = True,\n",
    "                  n_sim: int = N_SIM,\n",
    "                  seed: int = RNG_SEED):\n",
    "    \"\"\"\n",
    "    Interactive trade:\n",
    "      1) Shows matched rows for both players (for user verification)\n",
    "      2) If confirmed, swaps team_norm between the two selected rows (first match each)\n",
    "      3) Reruns season sim and returns Δ wins vs baseline\n",
    "\n",
    "    Notes:\n",
    "      - If multiple rows match a name, it uses the FIRST match; you can refine the query.\n",
    "      - Swap is only on team_norm (team assignment), not stats.\n",
    "    \"\"\"\n",
    "    base_summary = simulate_season(df_base, n_sim=n_sim, seed=seed)\n",
    "\n",
    "    m1, name_col = _find_player_rows(df_base, player1)\n",
    "    m2, _ = _find_player_rows(df_base, player2)\n",
    "\n",
    "    if len(m1) == 0 or len(m2) == 0:\n",
    "        raise ValueError(\n",
    "            f\"Player match failed. Matches: {player1}={len(m1)} rows, {player2}={len(m2)} rows.\\n\"\n",
    "            f\"Try more specific names.\"\n",
    "        )\n",
    "\n",
    "    # Preview key columns\n",
    "    preview_cols = [c for c in [\n",
    "        name_col, \"section\", \"role\", \"team_norm\", \"prev_league\",\n",
    "        \"OPS_final\", \"ERA_final\", \"PT\"\n",
    "    ] if c in df_base.columns]\n",
    "\n",
    "    print(\"\\n[PLAYER 1 MATCHES]\")\n",
    "    print(m1[preview_cols].head(10).to_string(index=True))\n",
    "    print(\"\\n[PLAYER 2 MATCHES]\")\n",
    "    print(m2[preview_cols].head(10).to_string(index=True))\n",
    "\n",
    "    # Choose first match per player\n",
    "    idx1 = m1.index[0]\n",
    "    idx2 = m2.index[0]\n",
    "\n",
    "    if confirm:\n",
    "        ans = input(\"\\nProceed with trade by swapping these two players' teams? (y/n): \").strip().lower()\n",
    "        if ans not in (\"y\", \"yes\"):\n",
    "            print(\"Trade cancelled.\")\n",
    "            return base_summary, None, None\n",
    "\n",
    "    # Apply swap\n",
    "    df_new = df_base.copy()\n",
    "    t1 = df_new.loc[idx1, \"team_norm\"]\n",
    "    t2 = df_new.loc[idx2, \"team_norm\"]\n",
    "    df_new.loc[idx1, \"team_norm\"] = t2\n",
    "    df_new.loc[idx2, \"team_norm\"] = t1\n",
    "\n",
    "    new_summary = simulate_season(df_new, n_sim=n_sim, seed=seed)\n",
    "\n",
    "    # Δ wins table\n",
    "    delta = new_summary.merge(\n",
    "        base_summary[[\"team\", \"Wins_mean\"]],\n",
    "        on=\"team\",\n",
    "        how=\"left\",\n",
    "        suffixes=(\"_new\", \"_base\")\n",
    "    )\n",
    "    delta[\"Delta_Wins_mean\"] = delta[\"Wins_mean_new\"] - delta[\"Wins_mean_base\"]\n",
    "    delta = delta.sort_values(\"Delta_Wins_mean\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "    print(\"\\n[Δ WINS (mean) AFTER TRADE]\")\n",
    "    print(delta[[\"team\", \"Wins_mean_base\", \"Wins_mean_new\", \"Delta_Wins_mean\"]].to_string(index=False))\n",
    "\n",
    "    return base_summary, new_summary, delta\n",
    "\n",
    "# -----------------------------\n",
    "# USAGE EXAMPLE\n",
    "# -----------------------------\n",
    "# 1) See baseline:\n",
    "# print(baseline_summary)\n",
    "#\n",
    "# 2) Run a trade:\n",
    "# base, new, delta = trade_players(df0, \"Joo Hwan Choi\", \"Some Other Player\", confirm=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81555aad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            team          RS          RA  Expected_Wins  Wins_mean   Wins_p10  \\\n",
      "0  Samsung Lions  508.181806  465.714444      91.556810  91.413832  83.369079   \n",
      "1    SSG Landers  538.647222  525.950000      86.650616  86.689896  78.589792   \n",
      "2   Lotte Giants  531.245694  522.615556      86.070721  85.991454  78.002984   \n",
      "3       LG Twins  488.299583  494.544444      83.813989  83.932696  75.956077   \n",
      "4   Doosan Bears  537.494028  621.694444      73.574205  73.666017  66.030233   \n",
      "5     KIA Tigers  509.945394  636.788889      67.797609  67.635696  59.988322   \n",
      "6       NC Dinos  482.099167  614.204444      66.310550  66.222700  58.493276   \n",
      "7         KT Wiz  424.817028  556.407778      64.277679  64.310113  56.584571   \n",
      "8  Hanwha Eagles  519.426250  694.538889      62.774089  62.839820  55.180866   \n",
      "9  Kiwoom Heroes  482.429217  965.894444      37.173733  37.297776  31.736340   \n",
      "\n",
      "    Wins_p90  \n",
      "0  99.517119  \n",
      "1  95.153840  \n",
      "2  94.294880  \n",
      "3  92.088974  \n",
      "4  81.627762  \n",
      "5  75.379043  \n",
      "6  74.168077  \n",
      "7  72.212591  \n",
      "8  70.556865  \n",
      "9  43.124253  \n"
     ]
    }
   ],
   "source": [
    "print(baseline_summary)\n",
    "base, new, delta = trade_players(df0, \"Joo Hwan Choi\", \"Son Ah-seop\", confirm=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "281d51c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Sanity] Total mean wins: 719.9999999999999 (target 720)\n",
      "            team    RS_final    RA_final  Wins_mean   Wins_p10   Wins_p90\n",
      "0  Samsung Lions  601.470174  534.050389  88.149566  80.519848  95.853631\n",
      "1       LG Twins  593.082729  528.597889  88.058183  80.555095  95.757054\n",
      "2    SSG Landers  563.312694  545.483500  82.004178  74.268436  89.753665\n",
      "3   Lotte Giants  581.685701  605.308111  76.703503  69.144542  84.418238\n",
      "4  Hanwha Eagles  578.539062  645.994278  71.599710  63.982231  79.310091\n",
      "5   Doosan Bears  575.667118  647.029389  71.201295  63.834940  78.849338\n",
      "6       NC Dinos  569.396458  672.904889  67.584935  60.229762  75.231775\n",
      "7         KT Wiz  502.931068  595.017056  67.572337  60.019971  75.250954\n",
      "8     KIA Tigers  565.320506  674.984778  66.737088  59.435914  74.121541\n",
      "9  Kiwoom Heroes  516.690991  935.271389  40.389207  34.639856  46.297148\n",
      "\n",
      "Saved: kbo_2026_season_simulation_results_final.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import unicodedata\n",
    "\n",
    "# =============================\n",
    "# FILES\n",
    "# =============================\n",
    "ROSTER_INPUT_CSV = \"kbo_2026_prediction_dataset_adjusted.csv\"\n",
    "KBO_BATTING_TEAM_CSV = \"KBO_batting_2021_2025_merged.csv\"\n",
    "KBO_PITCHING_TEAM_CSV = \"KBO_pitching_2021_2025_merged.csv\"\n",
    "OUTPUT_CSV = \"kbo_2026_season_simulation_results_final.csv\"\n",
    "\n",
    "# =============================\n",
    "# LEAGUE CONSTANTS\n",
    "# =============================\n",
    "LEAGUE_OPS = 0.720\n",
    "LEAGUE_ERA = 4.50\n",
    "LEAGUE_RPA = 0.115\n",
    "GAMES = 144\n",
    "N_TEAMS = 10\n",
    "TOTAL_WINS_LEAGUE = (GAMES * N_TEAMS) / 2  # 720\n",
    "PYTH_EXP = 1.83\n",
    "\n",
    "# Monte Carlo\n",
    "N_SIM = 5000\n",
    "SIGMA_RS = 0.05\n",
    "SIGMA_RA = 0.07\n",
    "RNG_SEED = 42\n",
    "\n",
    "# Team-memory regression weights\n",
    "# alpha=1.0 -> pure roster model\n",
    "# alpha=0.0 -> pure last-season team results\n",
    "ALPHA_RS = 0.65\n",
    "ALPHA_RA = 0.65\n",
    "MEMORY_SEASON = 2025\n",
    "\n",
    "# =============================\n",
    "# TEAM NORMALIZATION (robust)\n",
    "# =============================\n",
    "def clean_text(s: str) -> str:\n",
    "    s = \"\" if s is None else str(s)\n",
    "    s = unicodedata.normalize(\"NFKC\", s)\n",
    "    s = s.replace(\"\\u200b\", \"\").replace(\"\\xa0\", \" \")\n",
    "    return s.strip()\n",
    "\n",
    "def canonical_key(s: str) -> str:\n",
    "    s = clean_text(s)\n",
    "    s = re.sub(r\"\\s+\", \"\", s)\n",
    "    s = \"\".join(ch for ch in s if unicodedata.category(ch) not in (\"Cf\", \"Mn\"))\n",
    "    return s\n",
    "\n",
    "# Garbled keys seen in your data\n",
    "GARBLED_MAP = {\n",
    "    \"Ű\": \"Kiwoom Heroes\",\n",
    "    \"λ꺣\": \"Lotte Giants\",\n",
    "    \"Ｚ̿\": \"Samsung Lions\",\n",
    "    \"ȭ̱۽\": \"Doosan Bears\",\n",
    "    \"Ե ̾\": \"Hanwha Eagles\",\n",
    "}\n",
    "GARBLED_MAP_CANON = {canonical_key(k): v for k, v in GARBLED_MAP.items()}\n",
    "\n",
    "# Keyword rules (works for: Korean, English, abbreviations)\n",
    "TEAM_RULES = [\n",
    "    (\"Kiwoom Heroes\",   [r\"키움\", r\"히어로\", r\"kiwoom\", r\"heroes\"]),\n",
    "    (\"SSG Landers\",     [r\"ssg\", r\"랜더\", r\"landers\", r\"wyvern\", r\"sk\\s*wyvern\", r\"skwyverns\"]),\n",
    "    (\"LG Twins\",        [r\"\\blg\\b\", r\"트윈\", r\"twins\"]),\n",
    "    (\"KIA Tigers\",      [r\"\\bkia\\b\", r\"타이거\", r\"tigers\"]),\n",
    "    (\"KT Wiz\",          [r\"\\bkt\\b\", r\"위즈\", r\"wiz\"]),\n",
    "    (\"NC Dinos\",        [r\"\\bnc\\b\", r\"다이노\", r\"dinos\"]),\n",
    "    (\"Doosan Bears\",    [r\"두산\", r\"베어\", r\"doosan\", r\"bears\"]),\n",
    "    (\"Lotte Giants\",    [r\"롯데\", r\"자이언\", r\"lotte\", r\"giants\"]),\n",
    "    (\"Samsung Lions\",   [r\"삼성\", r\"라이온\", r\"samsung\", r\"lions\"]),\n",
    "    (\"Hanwha Eagles\",   [r\"한화\", r\"이글\", r\"hanwha\", r\"eagles\"]),\n",
    "]\n",
    "CANON_TEAMS = [\n",
    "    \"Kiwoom Heroes\",\"SSG Landers\",\"LG Twins\",\"KIA Tigers\",\"KT Wiz\",\n",
    "    \"NC Dinos\",\"Doosan Bears\",\"Lotte Giants\",\"Samsung Lions\",\"Hanwha Eagles\"\n",
    "]\n",
    "\n",
    "def normalize_team(s: str) -> str:\n",
    "    x = clean_text(s)\n",
    "    if x == \"\" or x.lower() == \"nan\":\n",
    "        return None\n",
    "\n",
    "    k = canonical_key(x)\n",
    "    if k in GARBLED_MAP_CANON:\n",
    "        return GARBLED_MAP_CANON[k]\n",
    "\n",
    "    x_low = x.lower()\n",
    "    for canon, pats in TEAM_RULES:\n",
    "        for pat in pats:\n",
    "            if re.search(pat, x_low):\n",
    "                return canon\n",
    "\n",
    "    if x in CANON_TEAMS:\n",
    "        return x\n",
    "\n",
    "    return None\n",
    "\n",
    "# =============================\n",
    "# TEAM-MEMORY: get RS/RA from 2025 team stats\n",
    "# =============================\n",
    "def load_team_memory_rs_ra(season=MEMORY_SEASON, games=GAMES):\n",
    "    bat = pd.read_csv(KBO_BATTING_TEAM_CSV)\n",
    "    pit = pd.read_csv(KBO_PITCHING_TEAM_CSV)\n",
    "\n",
    "    for d in (bat, pit):\n",
    "        if \"season\" not in d.columns:\n",
    "            raise ValueError(\"Expected a 'season' column in team-level KBO files.\")\n",
    "        if \"Tm\" not in d.columns:\n",
    "            raise ValueError(\"Expected a 'Tm' column in team-level KBO files (team name).\")\n",
    "\n",
    "    if \"R/G\" not in bat.columns:\n",
    "        raise ValueError(\"Expected 'R/G' in KBO_batting_2021_2025_merged.csv\")\n",
    "    if \"RA9\" not in pit.columns:\n",
    "        raise ValueError(\"Expected 'RA9' in KBO_pitching_2021_2025_merged.csv\")\n",
    "\n",
    "    bat = bat[bat[\"season\"] == season].copy()\n",
    "    pit = pit[pit[\"season\"] == season].copy()\n",
    "\n",
    "    # remove league totals / aggregate rows\n",
    "    bat = bat[~bat[\"Tm\"].astype(str).str.contains(\"League Totals\", case=False, na=False)].copy()\n",
    "    pit = pit[~pit[\"Tm\"].astype(str).str.contains(\"League Totals\", case=False, na=False)].copy()\n",
    "\n",
    "    bat[\"team_norm\"] = bat[\"Tm\"].apply(normalize_team)\n",
    "    pit[\"team_norm\"] = pit[\"Tm\"].apply(normalize_team)\n",
    "\n",
    "    bat_fail = bat[bat[\"team_norm\"].isna()][\"Tm\"].value_counts()\n",
    "    pit_fail = pit[pit[\"team_norm\"].isna()][\"Tm\"].value_counts()\n",
    "    if len(bat_fail) > 0 or len(pit_fail) > 0:\n",
    "        print(\"\\n[TEAM MEMORY NORMALIZATION FAILURES]\")\n",
    "        if len(bat_fail) > 0:\n",
    "            print(\"Batting team labels failing normalization:\")\n",
    "            print(bat_fail)\n",
    "        if len(pit_fail) > 0:\n",
    "            print(\"Pitching team labels failing normalization:\")\n",
    "            print(pit_fail)\n",
    "        raise ValueError(\"Fix TEAM_RULES to cover the team labels above.\")\n",
    "\n",
    "    bat[\"RS_mem\"] = bat[\"R/G\"].astype(float) * games\n",
    "    pit[\"RA_mem\"] = pit[\"RA9\"].astype(float) * games\n",
    "\n",
    "    mem = pd.merge(\n",
    "        bat[[\"team_norm\",\"RS_mem\"]],\n",
    "        pit[[\"team_norm\",\"RA_mem\"]],\n",
    "        on=\"team_norm\",\n",
    "        how=\"inner\"\n",
    "    )\n",
    "\n",
    "    assert mem[\"team_norm\"].nunique() == 10, f\"Expected 10 teams in memory, got {mem['team_norm'].nunique()}\"\n",
    "    return mem\n",
    "\n",
    "\n",
    "# =============================\n",
    "# CORE SIMULATOR\n",
    "# =============================\n",
    "def pythag_winpct(RS, RA, exp=PYTH_EXP):\n",
    "    RS = np.asarray(RS, dtype=float)\n",
    "    RA = np.asarray(RA, dtype=float)\n",
    "    return (RS**exp) / (RS**exp + RA**exp)\n",
    "\n",
    "def assign_playing_time(row):\n",
    "    STARTER_POS = {\"1B\",\"2B\",\"3B\",\"SS\",\"LF\",\"CF\",\"RF\",\"C\",\"DH\"}\n",
    "    if row[\"section\"] == \"Batters\":\n",
    "        return 520 if str(row[\"role\"]) in STARTER_POS else 220\n",
    "    r = str(row[\"role\"]).lower()\n",
    "    if r == \"starter\":\n",
    "        return 160\n",
    "    if r in {\"closer\",\"setup\"}:\n",
    "        return 65\n",
    "    return 45\n",
    "\n",
    "def simulate_season_with_team_memory(df_roster: pd.DataFrame,\n",
    "                                    alpha_rs=ALPHA_RS,\n",
    "                                    alpha_ra=ALPHA_RA,\n",
    "                                    n_sim=N_SIM,\n",
    "                                    seed=RNG_SEED):\n",
    "    df = df_roster.copy()\n",
    "\n",
    "    # regress missing player stats\n",
    "    df[\"OPS_final\"] = df[\"OPS_adj\"].fillna(LEAGUE_OPS)\n",
    "    df[\"ERA_final\"] = df[\"ERA_adj\"].fillna(LEAGUE_ERA)\n",
    "\n",
    "    # playing time\n",
    "    df[\"PT\"] = df.apply(assign_playing_time, axis=1)\n",
    "\n",
    "    # roster RS/RA contributions\n",
    "    df[\"RS_contrib\"] = np.where(\n",
    "        df[\"section\"] == \"Batters\",\n",
    "        df[\"PT\"] * (df[\"OPS_final\"] / LEAGUE_OPS) * LEAGUE_RPA,\n",
    "        0.0\n",
    "    )\n",
    "    df[\"RA_contrib\"] = np.where(\n",
    "        df[\"section\"] == \"Pitchers\",\n",
    "        df[\"PT\"] * df[\"ERA_final\"] / 9.0,\n",
    "        0.0\n",
    "    )\n",
    "\n",
    "    team_RS_roster = df.groupby(\"team_norm\")[\"RS_contrib\"].sum()\n",
    "    team_RA_roster = df.groupby(\"team_norm\")[\"RA_contrib\"].sum()\n",
    "\n",
    "    teams = pd.DataFrame({\n",
    "        \"team\": team_RS_roster.index.to_list(),\n",
    "        \"RS_roster\": team_RS_roster.values,\n",
    "        \"RA_roster\": team_RA_roster.reindex(team_RS_roster.index).values\n",
    "    })\n",
    "    assert len(teams) == 10, f\"Expected 10 teams, got {len(teams)}\"\n",
    "\n",
    "    # Load memory RS/RA from 2025 team stats and merge\n",
    "    mem = load_team_memory_rs_ra(season=MEMORY_SEASON, games=GAMES).rename(columns={\"team_norm\":\"team\"})\n",
    "    teams = teams.merge(mem, on=\"team\", how=\"left\")\n",
    "    assert teams[\"RS_mem\"].notna().all() and teams[\"RA_mem\"].notna().all(), \"Missing memory RS/RA for some teams.\"\n",
    "\n",
    "    # Team-memory regression blend\n",
    "    teams[\"RS_final\"] = alpha_rs * teams[\"RS_roster\"] + (1 - alpha_rs) * teams[\"RS_mem\"]\n",
    "    teams[\"RA_final\"] = alpha_ra * teams[\"RA_roster\"] + (1 - alpha_ra) * teams[\"RA_mem\"]\n",
    "\n",
    "    # Expected wins (scaled to 720)\n",
    "    winpct = pythag_winpct(teams[\"RS_final\"], teams[\"RA_final\"])\n",
    "    wins_raw = winpct * GAMES\n",
    "    teams[\"Expected_Wins\"] = wins_raw * (TOTAL_WINS_LEAGUE / wins_raw.sum())\n",
    "\n",
    "    # Monte Carlo (scaled to 720 each sim)\n",
    "    rng = np.random.default_rng(seed)\n",
    "    sim_wins = np.zeros((n_sim, len(teams)), dtype=float)\n",
    "\n",
    "    for i in range(n_sim):\n",
    "        RS_sim = teams[\"RS_final\"].values * rng.normal(1.0, SIGMA_RS, size=len(teams))\n",
    "        RA_sim = teams[\"RA_final\"].values * rng.normal(1.0, SIGMA_RA, size=len(teams))\n",
    "        RS_sim = np.clip(RS_sim, 1e-6, None)\n",
    "        RA_sim = np.clip(RA_sim, 1e-6, None)\n",
    "\n",
    "        winpct_i = pythag_winpct(RS_sim, RA_sim)\n",
    "        wins_i = winpct_i * GAMES\n",
    "        wins_i *= (TOTAL_WINS_LEAGUE / wins_i.sum())\n",
    "        sim_wins[i, :] = wins_i\n",
    "\n",
    "    sim_df = pd.DataFrame(sim_wins, columns=teams[\"team\"].values)\n",
    "\n",
    "    summary = pd.DataFrame({\n",
    "        \"team\": teams[\"team\"].values,\n",
    "        \"RS_roster\": teams[\"RS_roster\"].values,\n",
    "        \"RA_roster\": teams[\"RA_roster\"].values,\n",
    "        \"RS_mem_2025\": teams[\"RS_mem\"].values,\n",
    "        \"RA_mem_2025\": teams[\"RA_mem\"].values,\n",
    "        \"RS_final\": teams[\"RS_final\"].values,\n",
    "        \"RA_final\": teams[\"RA_final\"].values,\n",
    "        \"Expected_Wins\": teams[\"Expected_Wins\"].values,\n",
    "        \"Wins_mean\": sim_df.mean().values,\n",
    "        \"Wins_p10\": sim_df.quantile(0.10).values,\n",
    "        \"Wins_p90\": sim_df.quantile(0.90).values,\n",
    "    }).sort_values(\"Wins_mean\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "    return summary\n",
    "\n",
    "# =============================\n",
    "# RUN\n",
    "# =============================\n",
    "roster = pd.read_csv(ROSTER_INPUT_CSV)\n",
    "roster[\"team_norm\"] = roster[\"team\"].apply(normalize_team)\n",
    "assert roster[\"team_norm\"].notna().all(), \"Roster team normalization failed (update TEAM_RULES/GARBLED_MAP).\"\n",
    "assert roster[\"team_norm\"].nunique() == 10, f\"Expected 10 teams in roster, got {roster['team_norm'].nunique()}\"\n",
    "\n",
    "summary = simulate_season_with_team_memory(roster, alpha_rs=ALPHA_RS, alpha_ra=ALPHA_RA)\n",
    "\n",
    "print(\"\\n[Sanity] Total mean wins:\", float(summary[\"Wins_mean\"].sum()), \"(target 720)\")\n",
    "print(summary[[\"team\",\"RS_final\",\"RA_final\",\"Wins_mean\",\"Wins_p10\",\"Wins_p90\"]])\n",
    "\n",
    "summary.to_csv(OUTPUT_CSV, index=False)\n",
    "print(\"\\nSaved:\", OUTPUT_CSV)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
